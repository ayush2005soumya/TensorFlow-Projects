{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDZmI29tJz7c",
        "outputId": "25b6c46a-8bcd-4036-af09-ee434d4a5987"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "üñºÔ∏è Image: /content/drive/MyDrive/American_Staffordshire_Terrier(Cleo).JPG\n",
            "\n",
            "üí¨ Generated Text Description: a dog playing\n"
          ]
        }
      ],
      "source": [
        "from transformers import CLIPProcessor, CLIPModel\n",
        "import torch\n",
        "from PIL import Image\n",
        "from google.colab import drive # Import drive for mounting Google Drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load CLIP model and processor\n",
        "model_name = \"openai/clip-vit-base-patch16\"\n",
        "processor = CLIPProcessor.from_pretrained(model_name)\n",
        "model = CLIPModel.from_pretrained(model_name)\n",
        "\n",
        "# Load an image from Google Drive\n",
        "# Replace 'path/to/your/image.jpg' with the actual path to your image file in Google Drive\n",
        "image_path = \"/content/drive/MyDrive/American_Staffordshire_Terrier(Cleo).JPG\"\n",
        "\n",
        "# Open the image using PIL\n",
        "try:\n",
        "    image = Image.open(image_path)\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Image not found at {image_path}. Please verify the path to your image in Google Drive.\")\n",
        "    # You might want to exit or handle the error further here\n",
        "    exit() # Exit for demonstration purposes\n",
        "\n",
        "# Sample text descriptions to compare\n",
        "text_inputs = [\"a dog playing\", \"a cat on a bed\", \"a person playing soccer\", \"a computer programming book\"]\n",
        "\n",
        "# Preprocess image and text inputs\n",
        "inputs = processor(text=text_inputs, images=image, return_tensors=\"pt\", padding=True)\n",
        "\n",
        "# Get image-text similarity scores\n",
        "outputs = model(**inputs)\n",
        "logits_per_image = outputs.logits_per_image # Image-text similarity scores\n",
        "probs = logits_per_image.softmax(dim=1)  # Convert to probabilities\n",
        "\n",
        "# Get the most similar text description for the image\n",
        "best_match_idx = torch.argmax(probs)\n",
        "best_match = text_inputs[best_match_idx]\n",
        "\n",
        "# Display results\n",
        "print(f\"üñºÔ∏è Image: {image_path}\")\n",
        "print(f\"\\nüí¨ Generated Text Description: {best_match}\")"
      ]
    }
  ]
}