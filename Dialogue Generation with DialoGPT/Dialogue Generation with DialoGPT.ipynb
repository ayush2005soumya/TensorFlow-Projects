{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08fb0a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§‘ You: Hi there! How are you today?\n",
      "ðŸ¤– Bot: Hello and welcome!\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    " \n",
    "# Load pretrained DialoGPT model and tokenizer\n",
    "model_name = \"microsoft/DialoGPT-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    " \n",
    "# Conversation history (starts with a user prompt)\n",
    "chat_history_ids = None\n",
    "user_input = \"Hi there! How are you today?\"\n",
    " \n",
    "# Encode user input and append to chat history\n",
    "new_input_ids = tokenizer.encode(user_input + tokenizer.eos_token, return_tensors='pt')\n",
    "bot_input_ids = torch.cat([chat_history_ids, new_input_ids], dim=-1) if chat_history_ids is not None else new_input_ids\n",
    " \n",
    "# Generate response\n",
    "chat_history_ids = model.generate(\n",
    "    bot_input_ids,\n",
    "    max_length=1000,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    do_sample=True,\n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    "    temperature=0.8\n",
    ")\n",
    " \n",
    "# Decode and print bot response\n",
    "response = tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
    "print(\"ðŸ§‘ You:\", user_input)\n",
    "print(\"ðŸ¤– Bot:\", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
