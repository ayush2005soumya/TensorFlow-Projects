{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abd8da66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFBertForQuestionAnswering, BertTokenizer\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad0fd5b",
   "metadata": {},
   "source": [
    "# Load BERT QA model and tokenizer (TensorFlow version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78e3f75a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47a50773376648948069bddca5d9ee21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Dell\\.cache\\huggingface\\hub\\models--bert-large-uncased-whole-word-masking-finetuned-squad. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2020963618004cbea06314bcd0217fca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6425519b13184807a128321c70bcdbc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20fe719616234e3f8683963ed53eada7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/443 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe4f1454a8d94e9ebb5fad9fc9a75b27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForQuestionAnswering.\n",
      "\n",
      "All the weights of TFBertForQuestionAnswering were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForQuestionAnswering for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = TFBertForQuestionAnswering.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f31e3b",
   "metadata": {},
   "source": [
    "# Define context and question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbdf7aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"\n",
    "TensorFlow is an end-to-end open-source platform for machine learning. It has a comprehensive,\n",
    "flexible ecosystem of tools, libraries and community resources that lets researchers innovate\n",
    "with machine learning and productionize AI easily.\n",
    "\"\"\"\n",
    "question = \"What is TensorFlow used for?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd4779e",
   "metadata": {},
   "source": [
    "# Tokenize input, return TensorFlow tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68a76c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(question, context, return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0471722",
   "metadata": {},
   "source": [
    "# Run model (TensorFlow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e892ac54",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(inputs)\n",
    "\n",
    "start_logits = outputs.start_logits\n",
    "end_logits = outputs.end_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a893a8e",
   "metadata": {},
   "source": [
    "# Get the most likely beginning and end of answer span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "635e0d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = tf.argmax(start_logits, axis=1).numpy()[0]\n",
    "end_index = tf.argmax(end_logits, axis=1).numpy()[0] + 1  # +1 to include end token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0975b8",
   "metadata": {},
   "source": [
    "# Convert token ids to tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a7252a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_tokens = inputs['input_ids'][0][start_index:end_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd25d161",
   "metadata": {},
   "source": [
    "# Decode tokens to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e50bfeb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is TensorFlow used for?\n",
      "Answer: machine learning\n"
     ]
    }
   ],
   "source": [
    "answer = tokenizer.decode(answer_tokens, skip_special_tokens=True)\n",
    "\n",
    "print(\"Question:\", question)\n",
    "print(\"Answer:\", answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
