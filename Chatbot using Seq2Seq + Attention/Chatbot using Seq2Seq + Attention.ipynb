{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d79e802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd86c65",
   "metadata": {},
   "source": [
    "# Sample conversation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9a7ac99",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\"hi\", \"how are you\", \"what's your name\", \"bye\"]\n",
    "answers = [\"hello\", \"i'm fine\", \"i'm a chatbot\", \"goodbye\"]\n",
    " \n",
    "# Add <start> and <end> to target sentences\n",
    "answers = [f\"<start> {a} <end>\" for a in answers]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30de55e7",
   "metadata": {},
   "source": [
    "# Tokenize input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5a9d4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "a_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    " \n",
    "q_tokenizer.fit_on_texts(questions)\n",
    "a_tokenizer.fit_on_texts(answers)\n",
    " \n",
    "q_sequences = q_tokenizer.texts_to_sequences(questions)\n",
    "a_sequences = a_tokenizer.texts_to_sequences(answers)\n",
    " \n",
    "max_q_len = max(len(q) for q in q_sequences)\n",
    "max_a_len = max(len(a) for a in a_sequences)\n",
    " \n",
    "q_padded = tf.keras.preprocessing.sequence.pad_sequences(q_sequences, maxlen=max_q_len, padding='post')\n",
    "a_padded = tf.keras.preprocessing.sequence.pad_sequences(a_sequences, maxlen=max_a_len, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f77ce5",
   "metadata": {},
   "source": [
    "# Split decoder input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73649946",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = a_padded[:, :-1]\n",
    "decoder_target = tf.keras.utils.to_categorical(a_padded[:, 1:], num_classes=len(a_tokenizer.word_index) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7293040c",
   "metadata": {},
   "source": [
    "# Define attention mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e197435",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    " \n",
    "    def call(self, enc_output, dec_hidden):\n",
    "        dec_hidden = tf.expand_dims(dec_hidden, 1)\n",
    "        score = self.V(tf.nn.tanh(self.W1(enc_output) + self.W2(dec_hidden)))\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        context = attention_weights * enc_output\n",
    "        context_vector = tf.reduce_sum(context, axis=1)\n",
    "        return context_vector, attention_weights\n",
    "\n",
    "class RepeatContext(tf.keras.layers.Layer):\n",
    "    def call(self, context, decoder_outputs):\n",
    "        context = tf.expand_dims(context, 1)\n",
    "        context = tf.repeat(context, tf.shape(decoder_outputs)[1], axis=1)\n",
    "        return context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48951aaa",
   "metadata": {},
   "source": [
    "# Define layers for reuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31c2bff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 64\n",
    "lstm_units = 64\n",
    "vocab_inp_size = len(q_tokenizer.word_index) + 1\n",
    "vocab_tar_size = len(a_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21703aaf",
   "metadata": {},
   "source": [
    "# Define encoder model layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c75b541a",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = tf.keras.Input(shape=(max_q_len,))\n",
    "encoder_embedding_layer = tf.keras.layers.Embedding(vocab_inp_size, embedding_dim)\n",
    "encoder_lstm_layer = tf.keras.layers.LSTM(lstm_units, return_sequences=True, return_state=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e64626",
   "metadata": {},
   "source": [
    "# Apply encoder layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39c5c629",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_embedded = encoder_embedding_layer(encoder_inputs)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm_layer(encoder_embedded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ae62e8",
   "metadata": {},
   "source": [
    "# Define decoder layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a4d910a",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = tf.keras.Input(shape=(max_a_len - 1,))\n",
    "decoder_embedding_layer = tf.keras.layers.Embedding(vocab_tar_size, embedding_dim)\n",
    "decoder_lstm_layer = tf.keras.layers.LSTM(lstm_units, return_sequences=True, return_state=True)\n",
    "\n",
    "decoder_embedded = decoder_embedding_layer(decoder_inputs)\n",
    "decoder_outputs, _, _ = decoder_lstm_layer(decoder_embedded, initial_state=[state_h, state_c])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54b8005",
   "metadata": {},
   "source": [
    "# Attention mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a23f1014",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = BahdanauAttention(lstm_units)\n",
    "context_vector, _ = attention(encoder_outputs, state_h)\n",
    "context_vector_repeated = RepeatContext()(context_vector, decoder_outputs)\n",
    "\n",
    "concat = tf.keras.layers.Concatenate(axis=-1)([decoder_outputs, context_vector_repeated])\n",
    "final_output = tf.keras.layers.Dense(vocab_tar_size, activation='softmax')(concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b778ae0c",
   "metadata": {},
   "source": [
    "# Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "936d831d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model([encoder_inputs, decoder_inputs], final_output)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94237904",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d87869e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2a17c726540>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([q_padded, decoder_input], decoder_target, epochs=500, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9744d966",
   "metadata": {},
   "source": [
    "# Inference function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "973c1e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(input_text):\n",
    "    seq = q_tokenizer.texts_to_sequences([input_text])\n",
    "    seq = tf.keras.preprocessing.sequence.pad_sequences(seq, maxlen=max_q_len, padding='post')\n",
    "\n",
    "    # Encoder\n",
    "    enc_embed = encoder_embedding_layer(seq)\n",
    "    enc_out, h, c = encoder_lstm_layer(enc_embed)\n",
    "\n",
    "    # Decoder\n",
    "    dec_input = tf.constant([[a_tokenizer.word_index['<start>']]])\n",
    "    result = []\n",
    "\n",
    "    for _ in range(max_a_len):\n",
    "        dec_embed = decoder_embedding_layer(dec_input)\n",
    "        dec_out, h, c = decoder_lstm_layer(dec_embed, initial_state=[h, c])\n",
    "\n",
    "        context_vec, _ = attention(enc_out, h)\n",
    "        context_vec = tf.expand_dims(context_vec, 1)\n",
    "        context_vec = tf.repeat(context_vec, tf.shape(dec_out)[1], axis=1)\n",
    "\n",
    "        concat = tf.concat([dec_out, context_vec], axis=-1)\n",
    "        pred = tf.keras.layers.Dense(vocab_tar_size, activation='softmax')(concat)\n",
    "\n",
    "        token = tf.argmax(pred[:, -1, :], axis=-1).numpy()[0]\n",
    "        word = a_tokenizer.index_word.get(token, '')\n",
    "\n",
    "        if word == '<end>':\n",
    "            break\n",
    "        if word != '<start>':  # âœ… Skip start token in output\n",
    "            result.append(word)\n",
    "\n",
    "        dec_input = tf.constant([[token]])\n",
    "\n",
    "    return ' '.join(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c735a9a",
   "metadata": {},
   "source": [
    "# Try chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c03b4892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: hi\n",
      "Bot: goodbye  fine\n",
      "User: what's your name\n",
      "Bot: goodbye hello a goodbye goodbye\n",
      "User: bye\n",
      "Bot: a\n"
     ]
    }
   ],
   "source": [
    "print(\"User: hi\")\n",
    "print(\"Bot:\", chat(\"hi\"))\n",
    "print(\"User: what's your name\")\n",
    "print(\"Bot:\", chat(\"what's your name\"))\n",
    "print(\"User: bye\")\n",
    "print(\"Bot:\", chat(\"bye\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
