{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "504e914e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import itertools\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb513b82",
   "metadata": {},
   "source": [
    "# Sample corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78fb156f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"machine learning is fun\",\n",
    "    \"deep learning is part of machine learning\",\n",
    "    \"natural language processing is a field of ai\",\n",
    "    \"word embeddings are learned representations\",\n",
    "    \"tensorflow makes it easy to build models\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caf0403",
   "metadata": {},
   "source": [
    "# Tokenize corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ea7f64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "word2idx = tokenizer.word_index\n",
    "idx2word = {v: k for k, v in word2idx.items()}\n",
    "vocab_size = len(word2idx) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504397b5",
   "metadata": {},
   "source": [
    "# Generate skip-gram pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c45a23bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 2\n",
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "pairs = []\n",
    "for seq in sequences:\n",
    "    for i, target_word in enumerate(seq):\n",
    "        context_window = seq[max(i - window_size, 0): i] + seq[i + 1: i + window_size + 1]\n",
    "        for context_word in context_window:\n",
    "            pairs.append((target_word, context_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f900a0d4",
   "metadata": {},
   "source": [
    "# Convert to numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c85a88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets, contexts = zip(*pairs)\n",
    "targets = np.array(targets)\n",
    "contexts = np.array(contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fd410c",
   "metadata": {},
   "source": [
    "# One-hot encode targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05aa37ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_labels = tf.keras.utils.to_categorical(contexts, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a1d52e",
   "metadata": {},
   "source": [
    "# Define skip-gram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99382eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 64\n",
    "input_word = tf.keras.Input(shape=(1,))\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim)(input_word)\n",
    "x = tf.keras.layers.Reshape((embedding_dim,))(embedding)\n",
    "output = tf.keras.layers.Dense(vocab_size, activation='softmax')(x)\n",
    " \n",
    "model = tf.keras.Model(inputs=input_word, outputs=output)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78bf0d9",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dff7e83c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x23198180ec0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(targets, context_labels, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391a58d4",
   "metadata": {},
   "source": [
    "# Extract and display learned embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0d48e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning: [-0.009 -0.205  0.206 -0.239  0.193]\n",
      "is: [-0.12  -0.12  -0.042 -0.338  0.253]\n",
      "machine: [-0.15  -0.409  0.322 -0.168  0.271]\n",
      "of: [-0.2   -0.18   0.124 -0.124  0.241]\n",
      "fun: [-0.235 -0.246  0.29  -0.157  0.18 ]\n",
      "deep: [-0.273 -0.202  0.277 -0.229  0.182]\n",
      "part: [-0.276 -0.171  0.399 -0.286  0.236]\n",
      "natural: [-0.234  0.276 -0.207 -0.051  0.103]\n",
      "language: [-0.165  0.178 -0.184 -0.273 -0.022]\n",
      "processing: [-0.245  0.04  -0.067  0.047  0.258]\n",
      "a: [-0.206  0.039 -0.143 -0.238  0.24 ]\n",
      "field: [-0.143 -0.178  0.169  0.054  0.282]\n",
      "ai: [ 0.155 -0.224 -0.032 -0.222  0.258]\n",
      "word: [ 0.29   0.113 -0.129  0.257 -0.277]\n",
      "embeddings: [ 0.141 -0.274 -0.235  0.165 -0.228]\n",
      "are: [ 0.238  0.082 -0.05   0.181 -0.301]\n",
      "learned: [ 0.321  0.159  0.005  0.278 -0.246]\n",
      "representations: [ 0.288 -0.208 -0.184  0.179 -0.219]\n",
      "tensorflow: [-0.232  0.296  0.158 -0.305 -0.296]\n",
      "makes: [-0.117  0.32   0.25   0.119 -0.137]\n",
      "it: [ 0.176  0.165  0.212 -0.002 -0.165]\n",
      "easy: [-0.041  0.126  0.178 -0.205 -0.287]\n",
      "to: [-0.066  0.363  0.304  0.119 -0.153]\n",
      "build: [ 0.147  0.086  0.232  0.157 -0.145]\n",
      "models: [ 0.294 -0.023  0.227  0.012 -0.191]\n"
     ]
    }
   ],
   "source": [
    "embedding_weights = model.get_layer('embedding').get_weights()[0]\n",
    "for word, idx in word2idx.items():\n",
    "    vec = embedding_weights[idx][:5]  # Show first 5 dims\n",
    "    print(f\"{word}: {vec.round(3)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
