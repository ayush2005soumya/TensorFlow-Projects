{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f27727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import PegasusTokenizer, TFPegasusForConditionalGeneration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154fda9a",
   "metadata": {},
   "source": [
    "# Load tokenizer and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac2d977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82f5b185a4a14c50bfec8c180eab77a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "All PyTorch model weights were used when initializing TFPegasusForConditionalGeneration.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFPegasusForConditionalGeneration were not initialized from the PyTorch model and are newly initialized: ['model.encoder.embed_positions.weight', 'model.decoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"google/pegasus-cnn_dailymail\"\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "model = TFPegasusForConditionalGeneration.from_pretrained(model_name, from_pt=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a0c9f3",
   "metadata": {},
   "source": [
    "# Example long document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4eee0cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = \"\"\"\n",
    "Artificial Intelligence (AI) is transforming the world around us. From voice assistants and self-driving cars\n",
    "to medical diagnostics and financial predictions, AI systems are now integral to modern life. At its core, AI\n",
    "involves creating machines that can mimic human intelligence and improve themselves through data-driven learning.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da698a9b",
   "metadata": {},
   "source": [
    "# Tokenize input (with truncation and padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a68486",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(document, return_tensors=\"tf\", truncation=True, padding=\"longest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1739487f",
   "metadata": {},
   "source": [
    "# Generate Summary and Decode the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c77447a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: AI involves creating machines that can mimic human intelligence and improve themselves through data-driven learning .<n>From voice assistants and self-driving cars to medical diagnostics and financial predictions, AI systems are now integral to modern life .\n"
     ]
    }
   ],
   "source": [
    "summary_ids = model.generate(\n",
    "    input_ids=inputs[\"input_ids\"],\n",
    "    max_length=60,\n",
    "    num_beams=5,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Summary:\", summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
